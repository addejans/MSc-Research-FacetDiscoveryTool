{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries/Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scipy\n",
    "import scipy\n",
    "# numpy\n",
    "import numpy as np\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "# pandas\n",
    "import pandas\n",
    "# scikit-learn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Names of vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sorted_at-least1326.fm', 'sorted_at-least1345.fm', 'sorted_at-least1416.fm', 'sorted_at-least1426.fm', 'sorted_at-least1435.fm', 'sorted_at-least1445.fm', 'sorted_at-least1446.fm', 'sorted_at-least1456.fm', 'sorted_at-least1516.fm', 'sorted_at-least1526.fm', 'sorted_at-least1536.fm', 'sorted_at-least1556.fm', 'sorted_at-least1615.fm', 'sorted_at-least1625.fm', 'sorted_at-least1635.fm', 'sorted_at-least1645.fm', 'sorted_at-least2325.fm', 'sorted_at-least2326.fm', 'sorted_at-least2336.fm', 'sorted_at-least2416.fm', 'sorted_at-least2426.fm', 'sorted_at-least2436.fm', 'sorted_at-least2446.fm', 'sorted_at-least2456.fm', 'sorted_at-least2516.fm', 'sorted_at-least2526.fm', 'sorted_at-least2535.fm', 'sorted_at-least2536.fm', 'sorted_at-least2546.fm', 'sorted_at-least2615.fm', 'sorted_at-least2625.fm', 'sorted_at-least2635.fm', 'sorted_at-least2636.fm', 'sorted_at-least2645.fm', 'sorted_at-least2736.fm', 'sorted_at-least3416.fm', 'sorted_at-least3426.fm', 'sorted_at-least3436.fm', 'sorted_at-least3446.fm', 'sorted_at-least3456.fm', 'sorted_at-least3526.fm', 'sorted_at-least3536.fm', 'sorted_at-least3546.fm', 'sorted_at-least3556.fm', 'sorted_at-least3615.fm', 'sorted_at-least3625.fm', 'sorted_at-least3635.fm', 'sorted_at-least3645.fm', 'sorted_at-least4516.fm', 'sorted_at-least4526.fm', 'sorted_at-least4536.fm', 'sorted_at-least4546.fm', 'sorted_at-least4556.fm', 'sorted_at-least4615.fm', 'sorted_at-least4625.fm', 'sorted_at-least4635.fm', 'sorted_at-least4645.fm']\n"
     ]
    }
   ],
   "source": [
    "vec_Files = []\n",
    "with open('names') as g:\n",
    "    for line in g:\n",
    "        vec_Files.append(line.strip('\\n'))\n",
    "print (vec_Files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to map constraints to 5-tuple (& class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**FIVE LIST**********************\n",
      "**********************\n",
      "**********************\n",
      "**********************\n",
      "[0, 0, 3, 1.0, 14.0, 2.0]\n",
      "[1, -2.0, 2, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[2, -2.0, 1, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[3, -1.0, 0, 0, -2.0, 2.0]\n",
      "[1, -1.0, 2, 4.0, 36.0, 2.0]\n",
      "[2, -1.0, 1, 4.0, 16.0, 2.0]\n",
      "[0, 0, 3, 1.0, 14.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[3, -1.0, 0, 0, -4.0, 2.0]\n",
      "[0, 0, 4, 1.0, 19.0, 2.0]\n",
      "[1, -5.0, 3, 1.0, 13.0, 2.0]\n",
      "[2, -5.0, 2, 1.0, 7.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -5.0, 1, 1.0, 1.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -1.0, 2.0]\n",
      "[0, 0, 4, 1.0, 20.0, 2.0]\n",
      "[1, -2.0, 3, 1.0, 14.0, 2.0]\n",
      "[2, -2.0, 2, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -2.0, 1, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -2.0, 2.0]\n",
      "[1, -1.0, 3, 1.5, 19.5, 2.0]\n",
      "[0, 0, 4, 1.0, 18.0, 2.0]\n",
      "[2, -1.0, 2, 1.5, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[3, -1.0, 1, 1.5, 4.5, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -3.0, 2.0]\n",
      "[1, -1.0, 3, 4.0, 56.0, 2.0]\n",
      "[2, -1.0, 2, 4.0, 36.0, 2.0]\n",
      "[0, 0, 4, 1.0, 19.0, 2.0]\n",
      "[3, -1.0, 1, 4.0, 16.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -4.0, 2.0]\n",
      "[1, -1.0, 3, 2.0, 32.0, 2.0]\n",
      "[0, 0, 4, 1.0, 22.0, 2.0]\n",
      "[2, -1.0, 2, 2.0, 20.0, 2.0]\n",
      "[3, -1.0, 1, 2.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -4.0, 2.0]\n",
      "[1, -1.0, 3, 5.0, 85.0, 2.0]\n",
      "[2, -1.0, 2, 5.0, 55.0, 2.0]\n",
      "[3, -1.0, 1, 5.0, 25.0, 2.0]\n",
      "[0, 0, 4, 1.0, 23.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -5.0, 2.0]\n",
      "[0, 0, 5, 1.0, 25.0, 2.0]\n",
      "[1, -5.0, 4, 1.0, 19.0, 2.0]\n",
      "[2, -5.0, 3, 1.0, 13.0, 2.0]\n",
      "[3, -5.0, 2, 1.0, 7.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[4, -5.0, 1, 1.0, 1.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -1.0, 2.0]\n",
      "[0, 0, 5, 1.0, 26.0, 2.0]\n",
      "[1, -2.0, 4, 1.0, 20.0, 2.0]\n",
      "[2, -2.0, 3, 1.0, 14.0, 2.0]\n",
      "[3, -2.0, 2, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[4, -2.0, 1, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -2.0, 2.0]\n",
      "[0, 0, 5, 1.0, 27.0, 2.0]\n",
      "[1, -1.0, 4, 1.0, 21.0, 2.0]\n",
      "[2, -1.0, 3, 1.0, 15.0, 2.0]\n",
      "[3, -1.0, 2, 1.0, 9.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[4, -1.0, 1, 1.0, 3.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -3.0, 2.0]\n",
      "[1, -1.0, 4, 5.0, 115.0, 2.0]\n",
      "[2, -1.0, 3, 5.0, 85.0, 2.0]\n",
      "[3, -1.0, 2, 5.0, 55.0, 2.0]\n",
      "[0, 0, 5, 1.0, 29.0, 2.0]\n",
      "[4, -1.0, 1, 5.0, 25.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -5.0, 2.0]\n",
      "[0, 0, 6, 1.0, 26.0, 2.0]\n",
      "[1, -4.0, 5, 1.0, 21.0, 2.0]\n",
      "[2, -4.0, 4, 1.0, 16.0, 2.0]\n",
      "[3, -4.0, 3, 1.0, 11.0, 2.0]\n",
      "[4, -4.0, 2, 1.0, 6.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[5, -4.0, 1, 1.0, 1.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -1.0, 2.0]\n",
      "[0, 0, 6, 1.0, 27.0, 2.0]\n",
      "[1, -1.5, 5, 1.0, 22.0, 2.0]\n",
      "[2, -1.5, 4, 1.0, 17.0, 2.0]\n",
      "[3, -1.5, 3, 1.0, 12.0, 2.0]\n",
      "[4, -1.5, 2, 1.0, 7.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[5, -1.5, 1, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -2.0, 2.0]\n",
      "[1, -1.0, 5, 1.5, 34.5, 2.0]\n",
      "[0, 0, 6, 1.0, 28.0, 2.0]\n",
      "[2, -1.0, 4, 1.5, 27.0, 2.0]\n",
      "[3, -1.0, 3, 1.5, 19.5, 2.0]\n",
      "[4, -1.0, 2, 1.5, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[5, -1.0, 1, 1.5, 4.5, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -3.0, 2.0]\n",
      "[1, -1.0, 5, 4.0, 96.0, 2.0]\n",
      "[2, -1.0, 4, 4.0, 76.0, 2.0]\n",
      "[3, -1.0, 3, 4.0, 56.0, 2.0]\n",
      "[4, -1.0, 2, 4.0, 36.0, 2.0]\n",
      "[0, 0, 6, 1.0, 29.0, 2.0]\n",
      "[5, -1.0, 1, 4.0, 16.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -4.0, 2.0]\n",
      "[0, 0, 3, 1.0, 9.0, 2.0]\n",
      "[1, -1.5, 2, 1.0, 4.0, 2.0]\n",
      "[2, -1.5, 1, 1.0, -1.0, 2.0]\n",
      "[3, -1.0, 0, 0, -4.0, 2.0]\n",
      "[0, 0, 3, 1.0, 10.0, 2.0]\n",
      "[1, -2.0, 2, 1.0, 4.0, 2.0]\n",
      "[2, -2.0, 1, 1.0, -2.0, 2.0]\n",
      "[3, -1.0, 0, 0, -4.0, 2.0]\n",
      "[0, 0, 3, 1.0, 12.0, 2.0]\n",
      "[1, -1.0, 2, 1.0, 6.0, 2.0]\n",
      "[2, -1.0, 1, 1.0, 0.0, 2.0]\n",
      "[3, -1.0, 0, 0, -6.0, 2.0]\n",
      "[0, 0, 4, 1.0, 14.0, 2.0]\n",
      "[1, -5.0, 3, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[2, -5.0, 2, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -2.0, 2.0]\n",
      "[3, -5.0, 1, 1.0, -4.0, 2.0]\n",
      "[0, 0, 4, 1.0, 16.0, 2.0]\n",
      "[1, -2.0, 3, 1.0, 10.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[2, -2.0, 2, 1.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[3, -2.0, 1, 1.0, -2.0, 2.0]\n",
      "[4, -1.0, 0, 0, -4.0, 2.0]\n",
      "[0, 0, 4, 1.0, 18.0, 2.0]\n",
      "[1, -1.0, 3, 1.0, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[2, -1.0, 2, 1.0, 6.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[3, -1.0, 1, 1.0, 0.0, 2.0]\n",
      "[4, -1.0, 0, 0, -6.0, 2.0]\n",
      "[1, -1.0, 3, 2.0, 28.0, 2.0]\n",
      "[0, 0, 4, 1.0, 20.0, 2.0]\n",
      "[2, -1.0, 2, 2.0, 16.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -1.0, 1, 2.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -8.0, 2.0]\n",
      "[1, -1.0, 3, 5.0, 80.0, 2.0]\n",
      "[2, -1.0, 2, 5.0, 50.0, 2.0]\n",
      "[0, 0, 4, 1.0, 22.0, 2.0]\n",
      "[3, -1.0, 1, 5.0, 20.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 0, 0, -10.0, 2.0]\n",
      "[0, 0, 5, 1.0, 20.0, 2.0]\n",
      "[1, -5.0, 4, 1.0, 14.0, 2.0]\n",
      "[2, -5.0, 3, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -5.0, 2, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -2.0, 2.0]\n",
      "[4, -5.0, 1, 1.0, -4.0, 2.0]\n",
      "[0, 0, 5, 1.0, 22.0, 2.0]\n",
      "[1, -2.0, 4, 1.0, 16.0, 2.0]\n",
      "[2, -2.0, 3, 1.0, 10.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -2.0, 2, 1.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -2.0, 1, 1.0, -2.0, 2.0]\n",
      "[5, -1.0, 0, 0, -4.0, 2.0]\n",
      "[1, -1.0, 4, 1.5, 24.0, 2.0]\n",
      "[0, 0, 5, 1.0, 21.0, 2.0]\n",
      "[2, -1.0, 3, 1.5, 16.5, 2.0]\n",
      "[3, -1.0, 2, 1.5, 9.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[4, -1.0, 1, 1.5, 1.5, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -6.0, 2.0]\n",
      "[0, 0, 5, 1.0, 24.0, 2.0]\n",
      "[1, -1.0, 4, 1.0, 18.0, 2.0]\n",
      "[2, -1.0, 3, 1.0, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -1.0, 2, 1.0, 6.0, 2.0]\n",
      "[4, -1.0, 1, 1.0, 0.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -6.0, 2.0]\n",
      "[1, -1.0, 4, 2.0, 40.0, 2.0]\n",
      "[2, -1.0, 3, 2.0, 28.0, 2.0]\n",
      "[0, 0, 5, 1.0, 26.0, 2.0]\n",
      "[3, -1.0, 2, 2.0, 16.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[4, -1.0, 1, 2.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -8.0, 2.0]\n",
      "[0, 0, 6, 1.0, 22.0, 2.0]\n",
      "[1, -4.0, 5, 1.0, 17.0, 2.0]\n",
      "[2, -4.0, 4, 1.0, 12.0, 2.0]\n",
      "[3, -4.0, 3, 1.0, 7.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[4, -4.0, 2, 1.0, 2.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -2.0, 2.0]\n",
      "[5, -4.0, 1, 1.0, -3.0, 2.0]\n",
      "[0, 0, 6, 1.0, 24.0, 2.0]\n",
      "[1, -1.5, 5, 1.0, 19.0, 2.0]\n",
      "[2, -1.5, 4, 1.0, 14.0, 2.0]\n",
      "[3, -1.5, 3, 1.0, 9.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[4, -1.5, 2, 1.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.5, 1, 1.0, -1.0, 2.0]\n",
      "[6, -1.0, 0, 0, -4.0, 2.0]\n",
      "[1, -1.0, 5, 1.5, 31.5, 2.0]\n",
      "[0, 0, 6, 1.0, 26.0, 2.0]\n",
      "[2, -1.0, 4, 1.5, 24.0, 2.0]\n",
      "[3, -1.0, 3, 1.5, 16.5, 2.0]\n",
      "[4, -1.0, 2, 1.5, 9.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[5, -1.0, 1, 1.5, 1.5, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -6.0, 2.0]\n",
      "[0, 0, 6, 1.0, 30.0, 2.0]\n",
      "[1, -1.0, 5, 1.0, 24.0, 2.0]\n",
      "[2, -1.0, 4, 1.0, 18.0, 2.0]\n",
      "[3, -1.0, 3, 1.0, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[4, -1.0, 2, 1.0, 6.0, 2.0]\n",
      "[5, -1.0, 1, 1.0, 0.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -6.0, 2.0]\n",
      "[1, -1.0, 5, 4.0, 92.0, 2.0]\n",
      "[2, -1.0, 4, 4.0, 72.0, 2.0]\n",
      "[3, -1.0, 3, 4.0, 52.0, 2.0]\n",
      "[4, -1.0, 2, 4.0, 32.0, 2.0]\n",
      "[0, 0, 6, 1.0, 28.0, 2.0]\n",
      "[5, -1.0, 1, 4.0, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -8.0, 2.0]\n",
      "[0, 0, 7, 1.0, 36.0, 2.0]\n",
      "[1, -1.0, 6, 1.0, 30.0, 2.0]\n",
      "[2, -1.0, 5, 1.0, 24.0, 2.0]\n",
      "[3, -1.0, 4, 1.0, 18.0, 2.0]\n",
      "[4, -1.0, 3, 1.0, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[5, -1.0, 2, 1.0, 6.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 1, 1.0, 0.0, 2.0]\n",
      "[7, -1.0, 0, 0, -6.0, 2.0]\n",
      "[0, 0, 4, 1.0, 9.0, 2.0]\n",
      "[1, -5.0, 3, 1.0, 3.0, 2.0]\n",
      "[2, -5.0, 2, 1.0, -3.0, 2.0]\n",
      "[3, -5.0, 1, 1.0, -9.0, 2.0]\n",
      "[0, 0, 4, 1.0, 12.0, 2.0]\n",
      "[1, -2.0, 3, 1.0, 6.0, 2.0]\n",
      "[2, -2.0, 2, 1.0, 0.0, 2.0]\n",
      "[3, -2.0, 1, 1.0, -6.0, 2.0]\n",
      "[0, 0, 4, 1.0, 15.0, 2.0]\n",
      "[1, -1.0, 3, 1.0, 9.0, 2.0]\n",
      "[2, -1.0, 2, 1.0, 3.0, 2.0]\n",
      "[3, -1.0, 1, 1.0, -3.0, 2.0]\n",
      "[4, -1.0, 0, 0, -9.0, 2.0]\n",
      "[1, -1.0, 3, 2.0, 24.0, 2.0]\n",
      "[0, 0, 4, 1.0, 18.0, 2.0]\n",
      "[2, -1.0, 2, 2.0, 12.0, 2.0]\n",
      "[3, -1.0, 1, 2.0, 0.0, 2.0]\n",
      "[4, -1.0, 0, 0, -12.0, 2.0]\n",
      "[1, -1.0, 3, 5.0, 75.0, 2.0]\n",
      "[2, -1.0, 2, 5.0, 45.0, 2.0]\n",
      "[0, 0, 4, 1.0, 21.0, 2.0]\n",
      "[3, -1.0, 1, 5.0, 15.0, 2.0]\n",
      "[4, -1.0, 0, 0, -15.0, 2.0]\n",
      "[0, 0, 5, 1.0, 18.0, 2.0]\n",
      "[1, -2.0, 4, 1.0, 12.0, 2.0]\n",
      "[2, -2.0, 3, 1.0, 6.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[2, -2.0, 3, 1.0, 6.0, 2.0]\n",
      "[3, -2.0, 2, 1.0, 0.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[3, -2.0, 2, 1.0, 0.0, 2.0]\n",
      "[4, -2.0, 1, 1.0, -6.0, 2.0]\n",
      "[0, 0, 5, 1.0, 21.0, 2.0]\n",
      "[1, -1.0, 4, 1.0, 15.0, 2.0]\n",
      "[2, -1.0, 3, 1.0, 9.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[3, -1.0, 2, 1.0, 3.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 1, 1.0, -3.0, 2.0]\n",
      "[5, -1.0, 0, 0, -9.0, 2.0]\n",
      "[1, -1.0, 4, 2.0, 36.0, 2.0]\n",
      "[2, -1.0, 3, 2.0, 24.0, 2.0]\n",
      "[3, -1.0, 2, 2.0, 12.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[4, -1.0, 1, 2.0, 0.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.0, 1, 2.0, 0.0, 2.0]\n",
      "[5, -1.0, 0, 0, -12.0, 2.0]\n",
      "[1, -1.0, 4, 5.0, 105.0, 2.0]\n",
      "[2, -1.0, 3, 5.0, 75.0, 2.0]\n",
      "[3, -1.0, 2, 5.0, 45.0, 2.0]\n",
      "[0, 0, 5, 1.0, 27.0, 2.0]\n",
      "[4, -1.0, 1, 5.0, 15.0, 2.0]\n",
      "[0, 0, 1, 1.0, 6.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 0, 0, -15.0, 2.0]\n",
      "[0, 0, 6, 1.0, 18.0, 2.0]\n",
      "[1, -4.0, 5, 1.0, 13.0, 2.0]\n",
      "[2, -4.0, 4, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[3, -4.0, 3, 1.0, 3.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -4.0, 2, 1.0, -2.0, 2.0]\n",
      "[6, -1.0, 0, 0, -3.0, 2.0]\n",
      "[5, -4.0, 1, 1.0, -7.0, 2.0]\n",
      "[0, 0, 6, 1.0, 21.0, 2.0]\n",
      "[1, -1.5, 5, 1.0, 16.0, 2.0]\n",
      "[2, -1.5, 4, 1.0, 11.0, 2.0]\n",
      "[3, -1.5, 3, 1.0, 6.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[4, -1.5, 2, 1.0, 1.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.5, 1, 1.0, -4.0, 2.0]\n",
      "[6, -1.0, 0, 0, -6.0, 2.0]\n",
      "[1, -1.0, 5, 1.5, 28.5, 2.0]\n",
      "[0, 0, 6, 1.0, 24.0, 2.0]\n",
      "[2, -1.0, 4, 1.5, 21.0, 2.0]\n",
      "[3, -1.0, 3, 1.5, 13.5, 2.0]\n",
      "[4, -1.0, 2, 1.5, 6.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 1, 1.5, -1.5, 2.0]\n",
      "[6, -1.0, 0, 0, -9.0, 2.0]\n",
      "[1, -1.0, 5, 4.0, 88.0, 2.0]\n",
      "[2, -1.0, 4, 4.0, 68.0, 2.0]\n",
      "[3, -1.0, 3, 4.0, 48.0, 2.0]\n",
      "[4, -1.0, 2, 4.0, 28.0, 2.0]\n",
      "[0, 0, 6, 1.0, 27.0, 2.0]\n",
      "[5, -1.0, 1, 4.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -12.0, 2.0]\n",
      "[0, 0, 5, 1.0, 10.0, 2.0]\n",
      "[1, -5.0, 4, 1.0, 4.0, 2.0]\n",
      "[2, -5.0, 3, 1.0, -2.0, 2.0]\n",
      "[5, -1.0, 0, 0, -4.0, 2.0]\n",
      "[3, -5.0, 2, 1.0, -8.0, 2.0]\n",
      "[4, -5.0, 1, 1.0, -14.0, 2.0]\n",
      "[0, 0, 5, 1.0, 14.0, 2.0]\n",
      "[1, -2.0, 4, 1.0, 8.0, 2.0]\n",
      "[2, -2.0, 3, 1.0, 2.0, 2.0]\n",
      "[3, -2.0, 2, 1.0, -4.0, 2.0]\n",
      "[5, -1.0, 0, 0, -8.0, 2.0]\n",
      "[4, -2.0, 1, 1.0, -10.0, 2.0]\n",
      "[0, 0, 5, 1.0, 18.0, 2.0]\n",
      "[1, -1.0, 4, 1.0, 12.0, 2.0]\n",
      "[2, -1.0, 3, 1.0, 6.0, 2.0]\n",
      "[3, -1.0, 2, 1.0, 0.0, 2.0]\n",
      "[4, -1.0, 1, 1.0, -6.0, 2.0]\n",
      "[5, -1.0, 0, 0, -12.0, 2.0]\n",
      "[1, -1.0, 4, 2.0, 32.0, 2.0]\n",
      "[0, 0, 5, 1.0, 22.0, 2.0]\n",
      "[2, -1.0, 3, 2.0, 20.0, 2.0]\n",
      "[3, -1.0, 2, 2.0, 8.0, 2.0]\n",
      "[4, -1.0, 1, 2.0, -4.0, 2.0]\n",
      "[5, -1.0, 0, 0, -16.0, 2.0]\n",
      "[1, -1.0, 4, 5.0, 100.0, 2.0]\n",
      "[2, -1.0, 3, 5.0, 70.0, 2.0]\n",
      "[3, -1.0, 2, 5.0, 40.0, 2.0]\n",
      "[0, 0, 5, 1.0, 26.0, 2.0]\n",
      "[4, -1.0, 1, 5.0, 10.0, 2.0]\n",
      "[5, -1.0, 0, 0, -20.0, 2.0]\n",
      "[0, 0, 6, 1.0, 14.0, 2.0]\n",
      "[1, -4.0, 5, 1.0, 9.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[2, -4.0, 4, 1.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[3, -4.0, 3, 1.0, -1.0, 2.0]\n",
      "[6, -1.0, 0, 0, -4.0, 2.0]\n",
      "[4, -4.0, 2, 1.0, -6.0, 2.0]\n",
      "[5, -4.0, 1, 1.0, -11.0, 2.0]\n",
      "[0, 0, 6, 1.0, 18.0, 2.0]\n",
      "[1, -1.5, 5, 1.0, 13.0, 2.0]\n",
      "[2, -1.5, 4, 1.0, 8.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[3, -1.5, 3, 1.0, 3.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[4, -1.5, 2, 1.0, -2.0, 2.0]\n",
      "[5, -1.5, 1, 1.0, -7.0, 2.0]\n",
      "[6, -1.0, 0, 0, -8.0, 2.0]\n",
      "[1, -1.0, 5, 1.5, 25.5, 2.0]\n",
      "[0, 0, 6, 1.0, 22.0, 2.0]\n",
      "[2, -1.0, 4, 1.5, 18.0, 2.0]\n",
      "[3, -1.0, 3, 1.5, 10.5, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[4, -1.0, 2, 1.5, 3.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[5, -1.0, 1, 1.5, -4.5, 2.0]\n",
      "[6, -1.0, 0, 0, -12.0, 2.0]\n",
      "[1, -1.0, 5, 4.0, 84.0, 2.0]\n",
      "[2, -1.0, 4, 4.0, 64.0, 2.0]\n",
      "[3, -1.0, 3, 4.0, 44.0, 2.0]\n",
      "[0, 0, 6, 1.0, 26.0, 2.0]\n",
      "[4, -1.0, 2, 4.0, 24.0, 2.0]\n",
      "[0, 0, 1, 1.0, 5.0, 3.0]\n",
      "[5, -1.0, 1, 4.0, 4.0, 2.0]\n",
      "[1, -1.0, 0, 0, 0.0, 1.0]\n",
      "[6, -1.0, 0, 0, -16.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "def printReadIn():\n",
    "    print ('\\n**READ IN********************\\n**********************\\n**********************\\n**********************')\n",
    "    for i in range(len(vec_list)):\n",
    "        print (vec_list[i])\n",
    "        \n",
    "def printFiveList():\n",
    "    print ('\\n**FIVE LIST**********************\\n**********************\\n**********************\\n**********************')\n",
    "    for i in range(len(fiveList)):\n",
    "        print (fiveList[i])\n",
    "        \n",
    "def fiveDimList(org_list):\n",
    "    y = org_list[0] # first of the two coefficients \n",
    "    \n",
    "    new_list = []\n",
    "    tlst = []\n",
    "    \n",
    "    u = 0 # bound\n",
    "    v = 0 # classification integer\n",
    "    w = 0 # second of the two coefficients\n",
    "    x = 0 # counter 1\n",
    "    z = 0 # counter 2\n",
    "    \n",
    "    \n",
    "    for i in range(len(org_list)-2):\n",
    "        \n",
    "        tlst[:] = []\n",
    "        \n",
    "        if org_list[i] == y:\n",
    "            x += 1\n",
    "        elif org_list[i] != y:\n",
    "            w = org_list[i]\n",
    "            z += 1           \n",
    "                    \n",
    "    if z == 0 and w == 0:  #needs to be changed ???????????************************************ aribirary assignment ok?\n",
    "            z = 0\n",
    "            w = 0\n",
    "    \n",
    "    if y >= 0:   #do we have a mix of negatives and zero's or just positives and zeros\n",
    "        a = w\n",
    "        b = z\n",
    "        w = y\n",
    "        z = x\n",
    "        y = a\n",
    "        x = b\n",
    "        \n",
    "    v = org_list[len(org_list)-1]\n",
    "    u = org_list[len(org_list)-2]\n",
    "    tlst.append(x)\n",
    "    tlst.append(y)\n",
    "    tlst.append(z)\n",
    "    tlst.append(w)\n",
    "    tlst.append(u)\n",
    "    tlst.append(v)\n",
    "    new_list = tlst[:]\n",
    "        \n",
    "    return new_list\n",
    "\n",
    "#**DRIVER**\n",
    "\n",
    "vec_list = []\n",
    "temp_list = []\n",
    "#vec_Files = ['atleast1326.txt','atleast1345.txt','atleast1426.txt','atleast1435.txt', 'atleast1445.txt', 'atleast1536.txt', 'atleast2325.txt', 'atleast2326.txt', 'atleast2336.txt', 'atleast2436.txt', 'atleast2535.txt', 'atleast2546.txt', 'atleast2636.txt', 'atleast2736.txt']\n",
    "for fileN in vec_Files:\n",
    "    with open('sorted20171105_Reduced/' + fileN) as f:\n",
    "        for line in f:\n",
    "            temp_list[:] = []\n",
    "            for word in line.lower().split():\n",
    "                if word not in ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', '<=', '==']:\n",
    "                    temp_list.append(float(word))\n",
    "            #print temp_list\n",
    "            vec_list.append(temp_list[:]) \n",
    "            #print '\\n', vec_list\n",
    "#print (vec_list)\n",
    "fiveList = []\n",
    "\n",
    "'''\n",
    "for lst in vec_list:\n",
    "    if len(lst) == 0:\n",
    "        print ('\\n', lst)\n",
    "'''\n",
    "\n",
    "for lst in vec_list:\n",
    "    if len(lst) > 0: # to exclude the empty list that showed up\n",
    "        fiveList.append(fiveDimList(lst))  \n",
    "    #print ('\\n', fiveList)\n",
    "\n",
    "#printReadIn()\n",
    "printFiveList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Split into Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pandas.DataFrame(fiveList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:5]\n",
    "Y = array[:,5]\n",
    "validation_size = 0.20\n",
    "seed = 23\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "1.0     44\n",
      "2.0    334\n",
      "3.0     44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class distribution\n",
    "dataset = pandas.DataFrame(Y)\n",
    "dataset.columns = ['class']\n",
    "# class distribution\n",
    "print dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 10\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 1.000000 (0.000000)\n",
      "LDA: 0.997059 (0.008824)\n",
      "5-NN: 1.000000 (0.000000)\n",
      "CART: 1.000000 (0.000000)\n",
      "tree-gini: 1.000000 (0.000000)\n",
      "tree: 1.000000 (0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/blair/Windows/anaconda2/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdm-frst: 1.000000 (0.000000)\n",
      "SVM: 1.000000 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "from sklearn.neural_network import MLPClassifier #added new \n",
    "from sklearn import tree \n",
    "from sklearn import ensemble\n",
    "import sklearn \n",
    "models = [] \n",
    "models.append(('LR', LogisticRegression())) \n",
    "models.append(('LDA', LinearDiscriminantAnalysis())) \n",
    "models.append(('5-NN', KNeighborsClassifier())) \n",
    "#models.append(('1-NN', KNeighborsClassifier(n_neighbors=1))) \n",
    "#models.append(('3-NN', KNeighborsClassifier(n_neighbors=3))) \n",
    "#models.append(('9-NN', KNeighborsClassifier(n_neighbors=9))) \n",
    "#models.append(('15-NN', KNeighborsClassifier(n_neighbors=15))) \n",
    "models.append(('CART', DecisionTreeClassifier())) \n",
    "#models.append(('NB', GaussianNB())) \n",
    "models.append(('tree-gini', tree.DecisionTreeClassifier(criterion='gini'))) \n",
    "models.append(('tree', tree.DecisionTreeClassifier())) \n",
    "models.append(('rdm-frst', sklearn.ensemble.RandomForestClassifier())) \n",
    "models.append(('SVM', SVC())) \n",
    "#models.append(('MLP', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(50, 20), random_state=1))) \n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEVCAYAAADgh5I1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHmlJREFUeJzt3X24VWWB9/HvLwSdkvIFUhMUp6jgMUI7mqWF9qrV+F5K\nltRFWT1lXTb2qENTDg1ZjeVk2YtTvjAlaE4UNfmID4FJqXFIQIhR0TIRK8x8y1Sw3/PHuo8ut/tw\n9jlnHw5Hf5/r2hd73ete97rvDezfWvfaey/ZJiIi4lmD3YGIiNg6JBAiIgJIIERERJFAiIgIIIEQ\nERFFAiEiIoAEQrSJpIsk/esAtX2CpAWbWX+wpHUDse+hTtI/SfrWYPcjhoYEQvSKpMWS/ixp2y21\nT9vftf2mWh8s6UVbav+qfFTSKkl/kbRO0vckvWxL9aGvbH/W9vsGux8xNCQQomWSxgGvAQwcvoX2\nuc2W2E8Pvgx8DPgosBPwYuAHwFsHs1M92UpeuxhCEgjRGycC1wEXAdM2V1HS/5F0l6T1kt5XP6qX\n9DxJsyVtkHS7pE9KelZZ9x5JP5d0jqR7gDNL2ZKy/mdlFyskPSjpuNo+/1HSH8t+31srv0jS1yRd\nUbb5uaRdJf17Odv5H0n7dDOO8cCHgam2f2r7EdsPlbOWz/VyPPdKuk3Sq0v5HaW/0xr6+g1JV0l6\nQNLVkvasrf9y2e5+Scskvaa27kxJl0v6jqT7gfeUsu+U9duVdX8qfVkqaZey7gWS5ku6R9JaSe9v\naPeyMsYHJK2W1LG5v/8YmhII0RsnAt8tjzd3vZk0knQo8HHgDcCLgCkNVb4CPA/4+7LuROC9tfWv\nBG4Dng/Mqm9o+7Xl6cttb2/70rK8a2lzd2A6cJ6kHWubvgP4JDAKeAS4FvhVWb4c+FI3Y349sM72\nL7tZ3+p4VgI7A5cAc4H9qF6bdwFflbR9rf4JwGdK35ZTvd5dlgKTqc5ULgG+J2m72vojynh2aNgO\nqhB/HjC29OWDwF/LujnAOuAFwLHAZyW9vrbt4aXfOwDzga9u5vWIISqBEC2RdBCwJ3CZ7WXArcA7\nu6n+DuBC26ttPwT8S62dYcBxwBm2H7D9W+CLwLtr26+3/RXbm2z/ldZsBGba3mj7J8CDwEtq6+fZ\nXmb7YWAe8LDt2bYfAy4Fmp4hUL1x3tXdTlscz29sX1jb19jS10dsLwAepQqHLv9t+2e2HwFmAK+S\nNBbA9nds/6m8Nl8Etm0Y57W2f2D7b01eu41lPC+y/Vh5Pe4vbR8EnGb7YdvLgW81jGGJ7Z+UMfwn\n8PLuXpMYuhII0appwALbd5flS+h+2ugFwB215frzUcAI4PZa2e1UR/bN6rfqT7Y31ZYfAupH3X+o\nPf9rk+V63Se1C+y2mf22Mp7GfWF7c/t/fPy2HwTuoXpNu6bF1ki6T9K9VEf8o5pt28R/AlcCc8tU\n3hckDS9t32P7gc2M4fe15w8B2+UaxdNPAiF6JOnvqI76p0j6vaTfA6cAL5fU7EjxLmBMbXls7fnd\nVEeqe9bK9gDurC1vTT/BuxAYs5k581bG01uPv15lKmknYH25XnAa1d/FjrZ3AO4DVNu229eunD39\ni+2JwKuBt1FNb60HdpI0so1jiCEogRCtOBJ4DJhINX89GZgAXEP1htLoMuC9kiZIejbwqa4VZcrh\nMmCWpJHlgunHge/0oj9/oJqvH3C2bwG+BsxR9X2HEeXi7PGSTm/TeBq9RdJBkkZQXUu43vYdwEhg\nE7AB2EbSp4DnttqopEMkvaxMc91PFWSPlbZ/AZxVxjaJ6jpM4zWIeJpLIEQrplFdE/id7d93Pagu\nLJ7QOHVg+wrgXGARsJbqAi5UF3MBTgb+QnXheAnV9NMFvejPmcDF5ZMy7+jjmHrjo1RjPQ+4l+r6\nyVHAj8r6/o6n0SXAp6mmil5BdZEZqumeK4CbqaZ0HqZ302u7Ul1wvh9YA1zNE8E1FRhHdbYwD/i0\n7av6MYYYgpQb5MRAkzQBWAVs2zDPHw0kXUT1qaZPDnZf4pknZwgxICQdVaZXdgQ+D/woYRCxdUsg\nxED5ANVc961U1x8+NLjdiYieZMooIiKAnCFERESRQIiICCCBEBERRQIhIiKABEJERBQJhIiIABII\nERFRJBAiIgJIIERERJFAiIgIIIEQERFFAiEiIoAEQkREFAmEiIgAYJueq2w9Ro0a5XHjxg12NyIi\nhpRly5bdbXt0T/WGVCCMGzeOzs7Owe5GRMSQIun2VuplyigiIoAEQkREFAmEiIgAEggREVEkECIi\nAmgxECRdIOmPklZ1s16SzpW0VtJKSfvW1k2TdEt5TKuVv0LSjWWbcyWp/8OJiIi+avUM4SLg0M2s\nPwwYXx4nAV8HkLQT8GnglcD+wKcl7Vi2+Xqp27Xd5tqPiIgB1lIg2P4ZcM9mqhwBzHblOmAHSbsB\nbwausn2P7T8DVwGHlnXPtX2tbQOzgSP7NZKIiOiXdn0xbXfgjtryulK2ufJ1TcqfQtJJVGcS7LHH\nHq315szntVavt868r83tpZ/tbS/9bG97A9DPodBHeMb2s12B0Gz+330of2qhfT5wPkBHR0fTOk/R\n7r/MgZJ+tlf62V5DoZ9DoY8wZPrZrk8ZrQPG1pbHAOt7KB/TpDwiIgZJuwJhPnBi+bTRAcB9tu8C\nrgTeJGnHcjH5TcCVZd0Dkg4ony46Efhhm/oSERF90NKUkaQ5wMHAKEnrqD45NBzA9jeAnwBvAdYC\nDwHvLevukfQZYGlpaqbtrovTH6L69NLfAVeUR0REDBJVH/IZGjo6OpxfO42I6B1Jy2x39FQv31SO\niAgggRAREUUCISIigARCREQUCYSIiAASCBERUSQQIiICSCBERESRQIiICCCBEBERRQIhIiKABEJE\nRBQJhIiIABIIERFRJBAiIgJIIERERJFAiIgIIIEQERFFAiEiIoAEQkREFAmEiIgAEggREVEkECIi\nAkggRERE0VIgSDpU0k2S1ko6vcn6PSUtlLRS0mJJY2rrPi9pVXkcVyu/SNJvJC0vj8ntGVJERPRF\nj4EgaRhwHnAYMBGYKmliQ7Wzgdm2JwEzgbPKtm8F9gUmA68EPiHpubXtPmF7cnks7/doIiKiz1o5\nQ9gfWGv7NtuPAnOBIxrqTAQWlueLausnAlfb3mT7L8AK4ND+dzsiItqtlUDYHbijtryulNWtAI4p\nz48CRkrauZQfJunZkkYBhwBja9vNKtNM50jatk8jiIiItmglENSkzA3LpwJTJN0ATAHuBDbZXgD8\nBPgFMAe4FthUtjkDeCmwH7ATcFrTnUsnSeqU1Llhw4YWuhsREX3RSiCs48lH9WOA9fUKttfbPtr2\nPsCMUnZf+XNWuUbwRqpwuaWU3+XKI8CFVFNTT2H7fNsdtjtGjx7dy+FFRESrWgmEpcB4SXtJGgEc\nD8yvV5A0SlJXW2cAF5TyYWXqCEmTgEnAgrK8W/lTwJHAqv4PJyIi+mqbnirY3iTpI8CVwDDgAtur\nJc0EOm3PBw4GzpJk4GfAh8vmw4Frqvd87gfeZbtryui7kkZTnTUsBz7YvmFFRERvyW68HLD16ujo\ncGdn52B3IyJiSJG0zHZHT/XyTeWIiAASCBERUSQQIiICSCBERESRQIiICCCBEBERRQIhIiKABEJE\nRBQJhIiIABIIERFRJBAiIgJIIERERJFAiIgIIIEQERFFAiEiIoAEQkREFAmEiIgAEggREVEkECIi\nAkggREREkUCIiAgggRAREUUCISIigARCREQUCYSIiABaDARJh0q6SdJaSac3Wb+npIWSVkpaLGlM\nbd3nJa0qj+Nq5XtJul7SLZIulTSiPUOKiIi+6DEQJA0DzgMOAyYCUyVNbKh2NjDb9iRgJnBW2fat\nwL7AZOCVwCckPbds83ngHNvjgT8D0/s/nIiI6KtWzhD2B9bavs32o8Bc4IiGOhOBheX5otr6icDV\ntjfZ/guwAjhUkoDXAZeXehcDR/Z9GBER0V+tBMLuwB215XWlrG4FcEx5fhQwUtLOpfwwSc+WNAo4\nBBgL7Azca3vTZtoEQNJJkjoldW7YsKGVMUVERB+0EghqUuaG5VOBKZJuAKYAdwKbbC8AfgL8ApgD\nXAtsarHNqtA+33aH7Y7Ro0e30N2IiOiLVgJhHdVRfZcxwPp6BdvrbR9tex9gRim7r/w5y/Zk22+k\nCoJbgLuBHSRt012bERGxZbUSCEuB8eVTQSOA44H59QqSRknqausM4IJSPqxMHSFpEjAJWGDbVNca\nji3bTAN+2N/BRERE3/UYCGWe/yPAlcAa4DLbqyXNlHR4qXYwcJOkm4FdgFmlfDhwjaRfA+cD76pd\nNzgN+LiktVTXFL7dpjFFREQfqDpYHxo6Ojrc2dk52N2IiBhSJC2z3dFTvXxTOSIigARCREQUCYSI\niAASCBERUSQQIiICSCBERESRQIiICCCBEBERRQIhIiKABEJERBQJhIiIABIIERFRJBAiIgJIIERE\nRJFAiIgIIIEQERFFAiEiIoAEQkREFAmEiIgAEggREVEkECIiAkggREREkUCIiAgggRAREUUCISIi\ngBYDQdKhkm6StFbS6U3W7ylpoaSVkhZLGlNb9wVJqyWtkXSuJJXyxaXN5eXx/PYNKyIieqvHQJA0\nDDgPOAyYCEyVNLGh2tnAbNuTgJnAWWXbVwMHApOAvYH9gCm17U6wPbk8/tjfwURERN+1coawP7DW\n9m22HwXmAkc01JkILCzPF9XWG9gOGAFsCwwH/tDfTkdERPu1Egi7A3fUlteVsroVwDHl+VHASEk7\n276WKiDuKo8rba+pbXdhmS76566ppEaSTpLUKalzw4YNLXQ3IiL6opVAaPZG7YblU4Epkm6gmhK6\nE9gk6UXABGAMVYi8TtJryzYn2H4Z8JryeHeznds+33aH7Y7Ro0e30N2IiOiLVgJhHTC2tjwGWF+v\nYHu97aNt7wPMKGX3UZ0tXGf7QdsPAlcAB5T1d5Y/HwAuoZqaioiIQdJKICwFxkvaS9II4Hhgfr2C\npFGSuto6A7igPP8d1ZnDNpKGU509rCnLo8q2w4G3Aav6P5yIiOirHgPB9ibgI8CVwBrgMturJc2U\ndHipdjBwk6SbgV2AWaX8cuBW4Eaq6wwrbP+I6gLzlZJWAsupppj+o22jioiIXpPdeDlg69XR0eHO\nzs7B7kZExJAiaZntjp7q5ZvKEREBJBAiIqJIIEREBJBAiIiIIoEQERFAAiEiIooEQkREAAmEiIgo\nEggREQEkECIiokggREQEkECIiIgigRAREUACISIiigRCREQACYSIiCgSCBERASQQIiKiSCBERASQ\nQIiIiCKBEBERQAIhIiKKBEJERAAJhIiIKFoKBEmHSrpJ0lpJpzdZv6ekhZJWSlosaUxt3RckrZa0\nRtK5klTKXyHpxtLm4+URETE4egwEScOA84DDgInAVEkTG6qdDcy2PQmYCZxVtn01cCAwCdgb2A+Y\nUrb5OnASML48Du3vYCIiou9aOUPYH1hr+zbbjwJzgSMa6kwEFpbni2rrDWwHjAC2BYYDf5C0G/Bc\n29faNjAbOLJfI4mIiH5pJRB2B+6oLa8rZXUrgGPK86OAkZJ2tn0tVUDcVR5X2l5Ttl/XQ5sREbEF\ntRIIzeb23bB8KjBF0g1UU0J3ApskvQiYAIyhesN/naTXtthmtXPpJEmdkjo3bNjQQncjIqIvWgmE\ndcDY2vIYYH29gu31to+2vQ8wo5TdR3W2cJ3tB20/CFwBHFDaHLO5Nmttn2+7w3bH6NGjWxxWRET0\nViuBsBQYL2kvSSOA44H59QqSRknqausM4ILy/HdUZw7bSBpOdfawxvZdwAOSDiifLjoR+GEbxhMR\nEX3UYyDY3gR8BLgSWANcZnu1pJmSDi/VDgZuknQzsAswq5RfDtwK3Eh1nWGF7R+VdR8CvgWsLXWu\naMuIIiKiT1R9yGdo6OjocGdn52B3IyJiSJG0zHZHT/XyTeWIiAASCBERUSQQIiICSCBERESRQIiI\nCCCBEBERRQIhIiKABEJERBQJhIiIABIIERFRJBAiIgJIIERERJFAiIgIIIEQERFFAiEiIoAEQkRE\nFAmEiIgAEggREVEkECIiAkggREREkUCIiAgggRAREUUCISIigARCREQUCYSIiABaDARJh0q6SdJa\nSac3Wb+npIWSVkpaLGlMKT9E0vLa42FJR5Z1F0n6TW3d5PYOLSIiemObnipIGgacB7wRWAcslTTf\n9q9r1c4GZtu+WNLrgLOAd9teBEwu7ewErAUW1Lb7hO3L2zOUiIjoj1bOEPYH1tq+zfajwFzgiIY6\nE4GF5fmiJusBjgWusP1QXzsbEREDp5VA2B24o7a8rpTVrQCOKc+PAkZK2rmhzvHAnIayWWWa6RxJ\n2zbbuaSTJHVK6tywYUML3Y2IiL5oJRDUpMwNy6cCUyTdAEwB7gQ2Pd6AtBvwMuDK2jZnAC8F9gN2\nAk5rtnPb59vusN0xevToFrobERF90eM1BKozgrG15THA+noF2+uBowEkbQ8cY/u+WpV3APNsb6xt\nc1d5+oikC6lCJSIiBkkrZwhLgfGS9pI0gmrqZ369gqRRkrraOgO4oKGNqTRMF5WzBiQJOBJY1fvu\nR0REu/QYCLY3AR+hmu5ZA1xme7WkmZIOL9UOBm6SdDOwCzCra3tJ46jOMK5uaPq7km4EbgRGAf/a\nr5FERES/yG68HLD16ujocGdn52B3IyJiSJG0zHZHT/XyTeWIiAASCBERUSQQIiICSCBERESRQIiI\nCCCBEBERRQIhIiKABEJERBQJhIiIABIIERFRJBAiIgJIIERERJFAiIgIIIEQERFFAiEiIoAEQkRE\nFAmEiIgAEggREVEkECIiAkggREREkUCIiAgggbDVmzNnDnvvvTfDhg1j7733Zs6cOYPdpYh4mtpm\nsDsQ3ZszZw4zZszg29/+NgcddBBLlixh+vTpAEydOnWQexcRTzeyPdh9aFlHR4c7OzsHuxtbzN57\n781XvvIVDjnkkMfLFi1axMknn8yqVasGsWcRMZRIWma7o8d6CYSt17Bhw3j44YcZPnz442UbN25k\nu+2247HHHhvEnkXEUNJqILR0DUHSoZJukrRW0ulN1u8paaGklZIWSxpTyg+RtLz2eFjSkWXdXpKu\nl3SLpEsljejtIJ/uJkyYwJIlS55UtmTJEiZMmDBIPYqIp7MeA0HSMOA84DBgIjBV0sSGamcDs21P\nAmYCZwHYXmR7su3JwOuAh4AFZZvPA+fYHg/8GZjehvE8rcyYMYPp06ezaNEiNm7cyKJFi5g+fToz\nZswY7K5FxNNQKxeV9wfW2r4NQNJc4Ajg17U6E4FTyvNFwA+atHMscIXthySJKiDeWdZdDJwJfL23\nA3g667pwfPLJJ7NmzRomTJjArFmzckE5IgZEK4GwO3BHbXkd8MqGOiuAY4AvA0cBIyXtbPtPtTrH\nA18qz3cG7rW9qdbm7s12Lukk4CSAPfbYo4XuPr1MnTo1ARARW0Qr1xDUpKzxSvSpwBRJNwBTgDuB\nrjd7JO0GvAy4shdtVoX2+bY7bHeMHj26he5GRERftHKGsA4YW1seA6yvV7C9HjgaQNL2wDG276tV\neQcwz/bGsnw3sIOkbcpZwlPajIiILauVM4SlwPjyqaARVFM/8+sVJI2S1NXWGcAFDW1MBR7/iq2r\nz7ouorquADAN+GHvux8REe3SYyCUI/iPUE33rAEus71a0kxJh5dqBwM3SboZ2AWY1bW9pHFUZxhX\nNzR9GvBxSWupril8u18jiYiIfskX0yIinuaelt9UlrQBuL3NzY6iuqaxtRsK/RwKfYT0s93Sz/Ya\niH7uabvHT+UMqUAYCJI6W0nOwTYU+jkU+gjpZ7uln+01mP3Mz19HRASQQIiIiCKBAOcPdgdaNBT6\nORT6COlnu6Wf7TVo/XzGX0OIiIhKzhAiIgJ4hgWCpAeblJ0p6c5yv4ZfS9rivyTXQr9ukfT9xp8d\nlzRa0kZJHxjg/v1W0o2lL02/CCLJkr5YWz5V0pm1sTwk6fm19U8Zcz/6t6ukuZJuLX+HP5H04rLu\nlHIfjufV6h8s6T5JN0j6H0lnl/L31u7d8WhtzJ9roQ87SPrf7RpTqyR9q8nP0TfW+aCkE/vQ9qCM\nqRWS3iPpq/1sY065h8spPdcGSZMlvaUf+5shaXXZ53JJV0g6q8k+1pTnv5V0TcP65ZIG7HaJz6hA\n2Ixzyj0bjgC+KWl4TxtsIeeU+0mMBy4Ffiqp/lnitwPXUf00yEA7pPSlu4/DPQIcLWlUN+vvBv6x\n3Z0qP6U+D1hs+4W2JwL/RPWNeahem6VUv8Jbd43tfYB9gLdJOtD2hbX7d6zniTE/5aZQTewAPOXN\ns9xPZMDYfp/tX/dQ5xu2Z/eh+UEZUzOqtO39StKuwKttT7J9TsO67n7jbTLQp0CQ9CrgbcC+5b4x\nbwA+BxzXUPV44JLa8khJY0sbA35nrARCje1bqG7is+Ng96WR7Uupbi70zlrxVKo32TGSmv58+Ba0\niepiWHdHWxcAx0naqc37PQTYaPsbXQW2l9u+RtILge2BT9JNaNr+K7Ccbn5+vRc+B7ywHMEtlbRI\n0iXAjQCS3iXpl2X9N7veVCW9SdK1kn4l6XuqfhzySSQ9S9LXytHlj8sZ0LFl3WJJHeX5g5JmSVoh\n6TpJu5TyMyWdujWNqRWSxklaI+lrwK+Af5Z0s6SrgQNr9S6S9PXSv9skTZF0Qdn2om6aXwA8v/T9\nNeV1/Gxp+2OS3i5pVXktf6bqd9xmUv0bXi6p8Y28J7sBd9t+BMD23bavBu6VVL+dwDuAubXly3gi\nNJ70m3ADIYFQI2lf4BbbfxzsvnTjV8BLAcpRw662f8mT/9EMBAMLJC1TdX+K7pwHnKDa9EzNg1Sh\n8LE2921vYFk367r+A10DvES1KasuknYExgM/62c/TgduLWcXn6C6sdQM2xPLkd1xwIFl/WNUr9Mo\nqrB6g+19gU7g403aPhoYR/UT8u8DXtVNH54DXGf75WU879+Kx9SqlwCzqY7Mp1MFwRupbspVtyPV\nTbdOAX4EnAP8L+BlkiY3affwrrHZ7pqW2cH2FNtfBD4FvLm8lofbfrSUXVq2ubSX41gAjC2B9jVJ\nU0r5HKqzAiQdAPypHJh2uZzyS9LAP5SxDZgEQuUUSTcB11PduW1rVb+PxPFUQQDVEcVAThsdWP5z\nHwZ8WNJrm1WyfT/Vf96PdtPOucA0Sc8dmG4+xfHAXNt/A75PNcXW5TWSVgK/B35s+/dt3vcvbf+m\nPH898ApgqaTlZfnvgQOo3th+XsqnAXs2aesg4Hu2/1b6uaibfT4K/Lg8X0YVIu3UzjG16nbb11Hd\nlGux7Q3lzbnxDflH5VeUbwT+YPvG8ve+mtZfh3qbPwcukvR+oN9TZLYfpHq9TgI2AJdKeg/V/91j\ny3TY8Tz1DOAe4M+Sjqf6cdGH+tuXzWnlfgjPBOfYPlvS0cBsSS+0/fBgd6qJfaiOuKAKgF0knVCW\nXyBpfMPRRVuU+11g+4+S5lHdDOncsvob9eka4N+pzmQubNLOvWXKoZ0XKlfzxM+oP07SJKoj/6uq\nywyMAG6jOouB6hrC21RdfF4iaZ7t5W3s11/q3QEutn1GQx//AbjK9tSG8lcC3yyLn6L5DaWa2egn\nPkf+GO3//93nMbVpn5v7jPwj5c+/1Z53LW8j6Sjg06XsfTT/raDH92X7g+Xv4a3A8m7OMnrF9mPA\nYmCxpBuBabYvkvRbqhuLHUPzs79Lqf7dvqe/fehJzhBqbH+f6g132mD3pZGkY4A3AXMkvQR4ju3d\nbY+zPQ44i3Lq2eb9PkfSyK7npQ9Luy6+NoQBtu+hOnOZ3k2TXwI+QPverH4KbFuO5Lr6vB/V7VzP\n7Hp9bL8A2F3Sk45Wbd9M9dqd1s9+PACM7GbdQqqjwOeX/u1U+nEdcKCkF5XyZ0t6se3ra6/vfGAJ\ncEy5lrAL1c/NbwltG1Mb+nI9cLCknVV96OPtPW1QZ3te7TXt8SeTy0Hh9bY/RRUeY9n869FTey+R\nNL5WNJknfqhzDtUU16221zXZfB7wBZ644+SAeaYFwrMlras9ms1tzqS6T8OWfG2669cp5QLWLcC7\ngNfZ3kB1djCvoY3/YmCmjXahOoJeAfwS+G/b/7eHbb5I9YuNT2H7bqq+b9uOzpUj4qOAN6r62Olq\nqmm/g3nqazSP5qH5DeC1kvbqRz/+RDVNsgr4t4Z1v6aaV19QpqmuAnYrf5fvoQr5lVRvpi9t0vx/\nUd25cBXVmcP1wH1N6rXVAI+pt325i+rv9Vrg/1GdhQ6kf1P1seNVVNdjVlBN1U3s40Xl7YGLVX0s\neiXVtNqZZd33qK53zG22oe0HbH++TJUNqHxTOWIIkLS97Qcl7UwVzAcOwHWPeIbLNYSIoeHHknag\nuhbymYRBDIScIUREBPDMu4YQERHdSCBERASQQIiIiCKBEBERQAIhIiKKBEJERADw/wHh5/gcAwVV\nkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b12b3d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[ 8  0  0]\n",
      " [ 0 66  0]\n",
      " [ 0  0 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00         8\n",
      "        2.0       1.00      1.00      1.00        66\n",
      "        3.0       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "SVM = SVC()\n",
    "SVM.fit(X_train, Y_train)\n",
    "predictions = SVM.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[ 8  0  0]\n",
      " [ 0 66  0]\n",
      " [ 0  0 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00         8\n",
      "        2.0       1.00      1.00      1.00        66\n",
      "        3.0       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "predictions = LR.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[ 8  0  0]\n",
      " [ 0 66  0]\n",
      " [ 0  0 11]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       1.00      1.00      1.00         8\n",
      "        2.0       1.00      1.00      1.00        66\n",
      "        3.0       1.00      1.00      1.00        11\n",
      "\n",
      "avg / total       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "CART = DecisionTreeClassifier()\n",
    "CART.fit(X_train, Y_train)\n",
    "predictions = CART.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sci-Lab Code to Implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "function [z] = f(m,n,k)\n",
    "   z=n^2*m*k+n // function to solve for. black-boxed for us\n",
    "endfunction\n",
    "\n",
    "function [a] = co(m,n,k)\n",
    "    a = [1 m n k m*n m*k k*n m*n*k m^2*n m^2*k n^2*m n^2*k k^2*m k^2*n m^2 n^2 k^2 m^2*n^2 m^2*k^2 n^2*k^2 m^2*n^2*k^2 m^2*n^2*k m^2*k^2*n n^2*k^2*m m^2*n*k n^2*m*k k^2*m*n]\n",
    "endfunction\n",
    "\n",
    "A=[]\n",
    "b=[]\n",
    "for m = [1:3]\n",
    "    for n = [1:5]\n",
    "        for k = [1:8]\n",
    "            A = [A;co(m,n,k)]\n",
    "            b = [b;f(m,n,k)]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "SOLN = A\\b\n",
    "[A*SOLN,b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3863177  -0.92236578]\n",
      " [-0.92236578  0.3863177 ]]\n",
      "[[-0.24253563 -0.9701425 ]\n",
      " [-0.9701425   0.24253563]] \n",
      "\n",
      "\n",
      "[[-4.07578082 -5.38446431 -6.69314779]\n",
      " [ 0.62290503  0.08685696 -0.44919112]]\n",
      "[[-4.12310563 -5.33578375 -6.54846188]\n",
      " [ 0.         -0.72760688 -1.45521375]]\n"
     ]
    }
   ],
   "source": [
    "def factorizor(A):\n",
    "    B = scipy.linalg.orth(A)\n",
    "    C = (B.T).tolist()\n",
    "    \n",
    "    temp2 = [[] for column in B]\n",
    "    normlst = []\n",
    "    \n",
    "    \n",
    "    b = 0\n",
    "    f = 0\n",
    "    n = 0\n",
    "    i = 0\n",
    "    \n",
    "    for column in C:\n",
    "        for entry in column:\n",
    "            a = entry ** 2\n",
    "            temp2[n].append(a)\n",
    "        n += 1  \n",
    "    \n",
    "    for column in temp2:\n",
    "        for entry in column:\n",
    "            f += entry\n",
    "        \n",
    "        f ** 0.5\n",
    "        normlst.append(f)\n",
    "        f = 0\n",
    "        \n",
    "    n = 0\n",
    "    f = 0\n",
    "    temp2[:] = [[] for column in B]\n",
    "    \n",
    "    for column in B:\n",
    "        for entry in column:\n",
    "            b = entry/normlst[f]\n",
    "            temp2[n].append(b)\n",
    "        n += 1\n",
    "        f += 1\n",
    "    \n",
    "    Qarr = np.asarray(temp2)\n",
    "    \n",
    "    R = np.matmul(Qarr.T, A)\n",
    "    \n",
    "    return Qarr,R\n",
    "\n",
    "    \n",
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "Q1,R1 = factorizor(A)\n",
    "Q,R = np.linalg.qr(A)\n",
    "print Q1\n",
    "print Q, '\\n\\n'\n",
    "print R1\n",
    "print R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n",
      "422\n",
      "[[  0.   0.   3.   1.  14.]\n",
      " [  1.  -2.   2.   1.   8.]\n",
      " [  0.   0.   1.   1.   6.]\n",
      " ..., \n",
      " [  5.  -1.   1.   4.   4.]\n",
      " [  1.  -1.   0.   0.   0.]\n",
      " [  6.  -1.   0.   0. -16.]]\n",
      "\n",
      "\n",
      "\n",
      "***********  k-means++  **************************************************\n",
      "\n",
      "[2 0 0 0 0 0 2 2 2 0 0 0 2 2 0 0 0 0 0 2 2 0 0 0 0 0 2 2 2 0 0 0 0 1 2 2 2\n",
      " 0 0 0 2 2 2 0 0 0 0 1 1 2 2 0 0 0 2 2 2 0 0 0 0 0 2 2 2 0 0 0 0 0 2 2 2 0\n",
      " 0 0 0 0 1 1 1 2 2 0 0 0 2 2 2 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 2 2 2 2 2 0 0\n",
      " 0 0 1 1 1 2 2 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0\n",
      " 2 2 0 0 0 0 0 2 2 2 0 0 0 0 1 1 2 2 0 0 0 2 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0\n",
      " 2 2 2 0 0 0 0 0 2 2 2 0 0 0 0 0 2 2 2 2 0 0 0 0 2 2 2 0 0 0 0 0 0 2 2 2 0\n",
      " 0 0 0 0 0 2 2 2 2 0 0 0 0 0 2 2 2 2 0 0 0 0 0 1 1 1 2 2 2 0 0 0 2 2 2 2 2\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 2 2 2 0 0 1 2 2 2 0 2 2 0 0 0 0 0 0 0\n",
      " 2 2 0 0 0 0 0 0 2 2 2 0 0 0 0 0 1 1 2 2 2 0 0 0 2 2 0 0 0 0 0 0 0 2 2 2 0\n",
      " 0 0 0 0 0 2 2 2 2 0 0 0 0 0 1 1 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 2\n",
      " 0 0 0 0 2 2 2 0 0 0 1 1 2 2 0 0 2 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 2 2 2\n",
      " 0 0 0 0 0 0 1 1 2 2 2 0 0 0 0]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  MiniBatchKMeans  **************************************************\n",
      "\n",
      "[2 0 0 0 0 0 2 2 2 0 0 0 2 2 0 0 0 0 0 2 2 0 0 0 0 0 2 2 0 0 0 0 0 1 2 2 2\n",
      " 0 0 0 2 2 2 0 0 0 0 1 1 2 2 0 0 0 2 2 2 0 0 0 0 0 2 2 2 0 0 0 0 0 2 2 2 0\n",
      " 0 0 0 0 1 1 1 2 2 0 0 0 2 2 2 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 2 2 2 2 0 0 0\n",
      " 0 0 1 1 1 2 2 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0\n",
      " 2 2 0 0 0 0 0 2 2 2 0 0 0 0 1 1 2 2 0 0 0 2 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0\n",
      " 2 2 2 0 0 0 0 0 2 2 0 0 0 0 0 0 2 2 2 2 0 0 0 0 2 2 2 0 0 0 0 0 0 2 2 2 0\n",
      " 0 0 0 0 0 2 2 2 2 0 0 0 0 0 2 2 2 0 0 0 0 0 0 1 1 1 2 2 0 0 0 0 2 2 2 2 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 2 2 0 0 0 1 2 2 2 0 2 2 0 0 0 0 0 0 0\n",
      " 2 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 1 1 2 2 2 0 0 0 2 2 0 0 0 0 0 0 0 2 2 0 0\n",
      " 0 0 0 0 0 2 2 2 2 0 0 0 0 0 1 1 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 2\n",
      " 0 0 0 0 2 2 2 0 0 0 1 1 2 2 0 0 2 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 2 2 2\n",
      " 0 0 0 0 0 0 1 1 2 2 2 0 0 0 0]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  AffinityPropagation  **************************************************\n",
      "\n",
      "[39 51  0 20 20 20 43 47 39  1 20 53 30 39 51  2 20 20 20 30 39 51  3 20 20\n",
      " 53 30 30 39  4 18 20 53  8 43 30 47  5 20 53 54 28 30 51  6 20 53  7  8 28\n",
      " 28  9 20 53 28 30 39 51 10 20 20 53 28 30 39 51 11 20 20 53 54 30 30 51 12\n",
      " 18 20 53 45  7  8 54 28 13 20 53 54 30 30 39 51 14 20 20 53 54 28 30 39 51\n",
      " 15 20 20 53 43 54 54 30 39 16 51 20 53 45 36  8 43 54 47 17 20 53 24 18 20\n",
      " 53 39 19 20 53 39 13 20 53 39 51 21 19 20 53 53 30 39 22 19 20 20 53 30 39\n",
      " 23 51 20 20 53 54 30 30 24 18 20 42  7  8 28 47 25 20 42 30 39 51 26 19 20\n",
      " 53 53 28 30 39 27 19 20 53 53 28 30 30 51 29 20 20 53 28 30 39 31 51 20 20\n",
      " 53 43 54 28 47 32 51 20 42 28 30 39 51 33 19 20 53 53 28 30 39 51 37 51 20\n",
      " 53 53 54 54 28 30 51 34 20 20 53 54 28 30 39 35 51 20 20 53  7 36  8 43 54\n",
      " 47 37 20 42 43 54 28 30 39 38 51 20 20 53 39 19 53 42 39 51 20 53 30 39 18\n",
      " 53 42 28 30 39 20 49 36 46 30 47 49 30 39 51 40 51 20 20 20 53 30 30 51 41\n",
      " 18 20 53 42 43 28 39 44 20 20 20 49 45 36 46 54 47 48 20 49 30 39 51 50 19\n",
      " 20 53 53 42 30 30 39 51 52 20 20 53 53 54 28 28 39 51 55 20 53 42  7 36 46\n",
      " 54 54 51 56 20 42 39 19 20 53 42 49 39 51 19 53 42 42 30 39 51 20 53 49 54\n",
      " 28 30 51 53 49 45 36 46 28 47 49 39 39 57 19 20 20 53 53 42 30 39 51 58 18\n",
      " 20 53 42 42 28 28 30 39 50 18 20 53 42  7 36 46 54 28 59 51 20 49]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  MeanShift  **************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 4 3 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 4 3 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 3 1 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 3 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 3 2 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 4 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 2 1 1 0 0 0 0 0]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  SpectralClustering  **************************************************\n",
      "\n",
      "[0 2 2 2 2 2 0 0 0 2 2 2 0 2 2 2 2 2 2 0 0 2 2 2 2 2 0 0 2 2 2 2 2 0 0 0 0\n",
      " 2 2 2 0 0 0 2 2 1 2 0 0 0 0 2 1 2 0 0 2 2 2 2 1 2 0 0 0 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 0 0 0 0 0 2 2 2 0 0 0 2 2 2 2 2 2 0 0 0 2 2 2 2 2 2 0 0 0 0 2 2 2\n",
      " 2 2 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 0 2 2 2 1 2 2 0 0 0 2 2 1 2 0 0 0 0 2 1 2 0 2 2 2 2 1 2 2 0 0 2 2 2 1 2 2\n",
      " 0 0 0 2 2 2 1 2 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 2 2 2 2 2 2 0 0 0 0 0 2 2 2 2 0 0 0 0 2\n",
      " 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 0 2 2 2 0 0 0 0 2 0 0 2 2 2 2 2 2 2\n",
      " 0 0 2 2 2 2 2 2 0 0 2 2 2 2 2 2 0 0 0 0 0 2 2 2 0 2 2 2 2 2 2 2 2 0 0 2 2\n",
      " 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2\n",
      " 2 2 2 2 0 0 0 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0\n",
      " 2 2 2 2 2 2 0 0 0 0 0 2 2 1 2]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  Ward  **************************************************\n",
      "\n",
      "[0 2 2 2 2 2 0 0 0 2 2 2 0 0 2 2 2 2 2 0 0 2 2 2 2 2 0 0 0 2 2 2 2 0 0 0 0\n",
      " 2 2 2 0 0 0 2 2 2 2 1 0 0 0 2 2 2 0 0 0 2 2 2 2 2 0 0 0 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 1 1 0 0 0 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 0 2 2\n",
      " 2 2 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 0 0 2 2 2 2 2 0 0 0 2 2 2 2 1 0 0 0 2 2 2 0 0 2 2 2 2 2 2 0 0 2 2 2 2 2 2\n",
      " 0 0 0 2 2 2 2 2 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 0 0 0 2 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 1 1 0 0 0 2 2 2 2 0 0 0 0 0\n",
      " 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 0 0 2 2 1 0 0 0 2 0 0 2 2 2 2 2 2 2\n",
      " 0 0 2 2 2 2 2 2 0 0 0 2 2 2 2 2 1 1 0 0 0 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 2 0 0 0 0 2 2 2 2 2 1 1 0 0 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 0\n",
      " 2 2 2 2 0 0 0 2 2 2 1 1 0 0 2 2 0 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0\n",
      " 0 2 2 2 2 2 1 1 0 0 0 2 2 2 2]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  AgglomerativeClustering  **************************************************\n",
      "\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 1 1 1 1 1 0 0 2 1 1 1 1 1 1]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  DBSCAN  **************************************************\n",
      "\n",
      "[-1 -1  0 -1  1 -1 -1 -1 -1  2  1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1  0 -1  1\n",
      " -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1  2  1 -1 -1 -1 -1 -1  0  1 -1 -1 -1 -1\n",
      " -1  0  1 -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1  0\n",
      " -1  1 -1 -1 -1 -1 -1 -1  0  1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1 -1\n",
      "  2 -1  1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1 -1 -1  2  1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1\n",
      "  0 -1  1 -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1  0  1 -1 -1 -1 -1  0 -1  1\n",
      " -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1  0 -1 -1  1\n",
      " -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1 -1  2 -1  1\n",
      " -1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1  0 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1  2  1 -1 -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1 -1  1 -1 -1 -1 -1 -1  0\n",
      " -1  1 -1 -1 -1 -1 -1  0 -1  1 -1 -1 -1 -1 -1 -1 -1  0  1 -1 -1 -1 -1  2 -1\n",
      "  1 -1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1 -1 -1  2  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  2  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1 -1 -1  2 -1\n",
      "  1 -1 -1 -1 -1 -1 -1 -1  2 -1  1 -1 -1 -1 -1 -1 -1 -1  2 -1  1 -1]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  Birch  **************************************************\n",
      "\n",
      "[0 2 2 2 2 2 0 0 0 2 2 2 0 0 2 2 2 2 2 0 0 2 2 2 2 2 0 0 0 2 2 2 2 0 0 0 0\n",
      " 2 2 2 0 0 0 2 2 2 2 1 0 0 0 2 2 2 0 0 0 2 2 2 2 2 0 0 0 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 1 1 0 0 0 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 0 2 2\n",
      " 2 2 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 0 0 2 2 2 2 2 0 0 0 2 2 2 2 1 0 0 0 2 2 2 0 0 2 2 2 2 2 2 0 0 2 2 2 2 2 2\n",
      " 0 0 0 2 2 2 2 2 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 0 0 0 2 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 1 1 0 0 0 0 2 2 2 0 0 0 0 0\n",
      " 2 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 0 0 2 2 1 0 0 0 2 0 0 2 2 2 2 2 2 2\n",
      " 0 0 2 2 2 2 2 2 0 0 0 2 2 2 2 2 1 1 0 0 0 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0 2\n",
      " 2 2 2 2 2 0 0 0 0 2 2 2 2 2 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 0\n",
      " 2 2 2 2 0 0 0 2 2 2 1 1 0 0 0 2 0 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 0 0 0\n",
      " 0 2 2 2 2 2 1 1 0 0 0 2 2 2 2]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n",
      "\n",
      "\n",
      "\n",
      "***********  GaussianMixture  **************************************************\n",
      "\n",
      "[2 2 0 2 0 0 1 1 2 0 0 0 2 2 2 0 2 0 0 2 2 2 0 2 0 0 2 2 2 0 2 0 0 1 1 2 1\n",
      " 0 0 0 2 2 2 2 0 0 0 1 1 1 2 0 0 0 2 2 2 2 0 2 0 0 2 2 2 2 0 2 0 0 2 2 2 2\n",
      " 0 0 0 0 1 1 1 2 1 0 0 0 2 2 2 2 2 0 2 0 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 2\n",
      " 0 0 1 1 1 1 2 1 0 0 0 2 2 2 0 2 2 2 0 2 2 0 0 2 2 0 2 0 0 2 2 2 0 2 0 2 0\n",
      " 2 2 0 2 0 0 0 2 2 2 0 2 0 0 1 1 2 1 0 0 0 2 2 2 0 2 0 0 2 2 2 2 0 2 0 2 0\n",
      " 2 2 2 2 0 2 0 0 2 2 2 0 2 0 0 0 2 2 2 2 0 2 0 0 2 2 2 2 0 2 0 0 2 2 2 2 2\n",
      " 0 2 0 0 0 2 2 2 2 2 0 2 0 0 2 2 2 2 0 2 0 0 0 1 1 1 1 2 1 0 0 0 2 2 2 2 2\n",
      " 0 2 0 0 0 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 0 1 1 2 1 0 2 2 2 0 2 2 0 2 2\n",
      " 2 2 2 0 2 0 0 0 2 2 2 0 2 0 2 0 1 1 1 2 1 0 0 0 2 2 2 0 2 0 2 0 2 2 2 2 2\n",
      " 0 2 0 0 0 2 2 2 2 2 0 0 2 0 1 1 1 1 2 1 0 0 0 2 2 2 0 2 2 2 2 2 2 0 2 2 2\n",
      " 2 2 0 0 2 2 2 2 2 0 1 1 1 2 1 0 2 2 0 2 0 2 0 2 2 2 2 2 0 2 0 2 0 0 2 2 2\n",
      " 2 0 2 0 2 0 1 1 1 2 1 0 1 0 0]\n",
      "[ 2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.  3.  1.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.\n",
      "  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  3.  2.  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  3.  2.\n",
      "  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.\n",
      "  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.\n",
      "  1.  2.  2.  2.  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.\n",
      "  1.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  2.  1.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.\n",
      "  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  3.\n",
      "  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.\n",
      "  2.  3.  1.  2.  2.  2.  2.  2.  2.  2.  2.  3.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  2.  1.  2.  2.  2.  2.  2.  2.  2.  3.  2.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  2.  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html\n",
    "\n",
    "seed = 10\n",
    "\n",
    "print len(X)\n",
    "print len(Y)\n",
    "print X\n",
    "\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "\n",
    "\n",
    "# ============\n",
    "# Create cluster objects\n",
    "# ============\n",
    "params=3\n",
    "ms = cluster.MeanShift()#bandwidth=bandwidth, bin_seeding=True)\n",
    "two_means = cluster.MiniBatchKMeans(n_clusters=params)\n",
    "ward = cluster.AgglomerativeClustering(n_clusters=params, linkage='ward')#,connectivity=connectivity)\n",
    "spectral = cluster.SpectralClustering(n_clusters=params, eigen_solver='arpack',affinity=\"nearest_neighbors\")\n",
    "dbscan = cluster.DBSCAN()#eps=params['eps'])\n",
    "affinity_propagation = cluster.AffinityPropagation()#damping=params['damping'] preference=params['preference'])\n",
    "average_linkage = cluster.AgglomerativeClustering(linkage=\"average\", affinity=\"cityblock\", n_clusters=params)#, connectivity=connectivity)\n",
    "birch = cluster.Birch(n_clusters=params)\n",
    "gmm = mixture.GaussianMixture(n_components=params, covariance_type='full')\n",
    "#km = cluster.KMeans(init='k-means++', n_clusters=3)\n",
    "km = cluster.KMeans(n_clusters=3)\n",
    "\n",
    "clustering_algorithms = (\n",
    "    ('k-means++', km),\n",
    "    ('MiniBatchKMeans', two_means),\n",
    "    ('AffinityPropagation', affinity_propagation),\n",
    "    ('MeanShift', ms),\n",
    "    ('SpectralClustering', spectral),\n",
    "    ('Ward', ward),\n",
    "    ('AgglomerativeClustering', average_linkage),\n",
    "    ('DBSCAN', dbscan),\n",
    "    ('Birch', birch),\n",
    "    ('GaussianMixture', gmm)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for name, algorithm in clustering_algorithms:\n",
    "    print '\\n\\n\\n*********** ', name, ' **************************************************\\n'\n",
    "    count = 0\n",
    "    if name == 'GaussianMixture':\n",
    "        algorithm.fit(X)\n",
    "        why_prediction = algorithm.predict(X)\n",
    "        print why_prediction\n",
    "        print Y\n",
    "    elif name == 'DBSCAN':\n",
    "        algorithm.fit(X)\n",
    "        Y_prediction=algorithm.fit_predict(X)\n",
    "        print(Y_prediction)\n",
    "        print(Y)\n",
    "    else:\n",
    "        algorithm.fit(X)\n",
    "        why_prediction=algorithm.fit_predict(X)\n",
    "        print why_prediction\n",
    "        print Y\n",
    "    # Print out the first 100 instances of `y_pred`\n",
    "    \n",
    "    # Print out the first 100 instances of `y_test`\n",
    "    \n",
    "    \n",
    "    if name == 'DBSCAN':\n",
    "        for i in range(len(Y)):\n",
    "            if (Y_prediction[i] == -1):\n",
    "                if Y[i] != 2:\n",
    "                    print '******MISSCLASS ', Y[i], ' ', Y_prediction[i]\n",
    "            elif (Y_prediction[i] == 0 or Y_prediction[i] == 2):\n",
    "                if Y[i] != 3:\n",
    "                    print '******MISSCLASS ', Y[i], ' ', Y_prediction[i]\n",
    "            elif (Y_prediction[i] == 1):\n",
    "                if Y[i] != 1:\n",
    "                    print '******MISSCLASS ', Y[i], ' ', Y_prediction[i]\n",
    "            else:\n",
    "                print '*D*D*D** Double Class: ', Y[i], ' ', Y_prediction[i]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = Axes3D(plt.gcf())\n",
    "#ax.scatter( Xc[l], Yc[l], Zc[l], c=(i/nbodies,i/nbodies,i/nbodies))\n",
    "ax.scatter(X[:,4], X[:,3], X[:,1], zdir='z', s=20, c=Y, depthshade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----Testing Examples-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "# Compute Affinity Propagation\n",
    "af = AffinityPropagation(preference=-50).fit(X)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(Y, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(Y, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(Y, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(Y, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(Y, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels, metric='sqeuclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# ============\n",
    "# Set up cluster parameters\n",
    "# ============\n",
    "\n",
    "default_base = {'quantile': .3,\n",
    "                'eps': .3,\n",
    "                'damping': .9,\n",
    "                'preference': -200,\n",
    "                'n_neighbors': 10,\n",
    "                'n_clusters': 3}\n",
    "\n",
    "datasets = [(X,{})]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "#    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # ============\n",
    "    # Create cluster objects\n",
    "    # ============\n",
    "    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
    "    ward = cluster.AgglomerativeClustering(\n",
    "        n_clusters=params['n_clusters'], linkage='ward',\n",
    "        connectivity=connectivity)\n",
    "    spectral = cluster.SpectralClustering(\n",
    "        n_clusters=params['n_clusters'], eigen_solver='arpack',\n",
    "        affinity=\"nearest_neighbors\")\n",
    "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
    "    affinity_propagation = cluster.AffinityPropagation(\n",
    "        damping=params['damping'], preference=params['preference'])\n",
    "    average_linkage = cluster.AgglomerativeClustering(\n",
    "        linkage=\"average\", affinity=\"cityblock\",\n",
    "        n_clusters=params['n_clusters'], connectivity=connectivity)\n",
    "    birch = cluster.Birch(n_clusters=params['n_clusters'])\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=params['n_clusters'], covariance_type='full')\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        ('MiniBatchKMeans', two_means),\n",
    "        ('AffinityPropagation', affinity_propagation),\n",
    "        ('MeanShift', ms),\n",
    "        ('SpectralClustering', spectral),\n",
    "        ('Ward', ward),\n",
    "        ('AgglomerativeClustering', average_linkage),\n",
    "        ('DBSCAN', dbscan),\n",
    "        ('Birch', birch),\n",
    "        ('GaussianMixture', gmm)\n",
    "    )\n",
    "\n",
    "    for name, algorithm in clustering_algorithms:\n",
    "        t0 = time.time()\n",
    "\n",
    "        # catch warnings related to kneighbors_graph\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"the number of connected components of the \" +\n",
    "                \"connectivity matrix is [0-9]{1,2}\" +\n",
    "                \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                category=UserWarning)\n",
    "            warnings.filterwarnings(\n",
    "                \"ignore\",\n",
    "                message=\"Graph is not fully connected, spectral embedding\" +\n",
    "                \" may not work as expected.\",\n",
    "                category=UserWarning)\n",
    "            algorithm.fit(X)\n",
    "\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, 'labels_'):\n",
    "            y_pred = algorithm.labels_.astype(np.int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "        print y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZEROS CLUSTER   [[0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0], [0, 0, 1, 1.0, 6.0]] \n",
      "\n",
      "ONES CLUSTER   [[1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0], [1, -1.0, 0, 0, 0.0]] \n",
      "\n",
      "TWOS CLUSTER   [[0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0], [0, 0, 1, 1.0, 5.0]] \n",
      "\n",
      "NEGATIVE ONE CLUSTER   [[0, 0, 3, 1.0, 14.0], [1, -2.0, 2, 1.0, 8.0], [2, -2.0, 1, 1.0, 2.0], [3, -1.0, 0, 0, -2.0], [1, -1.0, 2, 4.0, 36.0], [2, -1.0, 1, 4.0, 16.0], [0, 0, 3, 1.0, 14.0], [3, -1.0, 0, 0, -4.0], [0, 0, 4, 1.0, 19.0], [1, -5.0, 3, 1.0, 13.0], [2, -5.0, 2, 1.0, 7.0], [3, -5.0, 1, 1.0, 1.0], [4, -1.0, 0, 0, -1.0], [0, 0, 4, 1.0, 20.0], [1, -2.0, 3, 1.0, 14.0], [2, -2.0, 2, 1.0, 8.0], [3, -2.0, 1, 1.0, 2.0], [4, -1.0, 0, 0, -2.0], [1, -1.0, 3, 1.5, 19.5], [0, 0, 4, 1.0, 18.0], [2, -1.0, 2, 1.5, 12.0], [3, -1.0, 1, 1.5, 4.5], [4, -1.0, 0, 0, -3.0], [1, -1.0, 3, 4.0, 56.0], [2, -1.0, 2, 4.0, 36.0], [0, 0, 4, 1.0, 19.0], [3, -1.0, 1, 4.0, 16.0], [4, -1.0, 0, 0, -4.0], [1, -1.0, 3, 2.0, 32.0], [0, 0, 4, 1.0, 22.0], [2, -1.0, 2, 2.0, 20.0], [3, -1.0, 1, 2.0, 8.0], [4, -1.0, 0, 0, -4.0], [1, -1.0, 3, 5.0, 85.0], [2, -1.0, 2, 5.0, 55.0], [3, -1.0, 1, 5.0, 25.0], [0, 0, 4, 1.0, 23.0], [4, -1.0, 0, 0, -5.0], [0, 0, 5, 1.0, 25.0], [1, -5.0, 4, 1.0, 19.0], [2, -5.0, 3, 1.0, 13.0], [3, -5.0, 2, 1.0, 7.0], [4, -5.0, 1, 1.0, 1.0], [5, -1.0, 0, 0, -1.0], [0, 0, 5, 1.0, 26.0], [1, -2.0, 4, 1.0, 20.0], [2, -2.0, 3, 1.0, 14.0], [3, -2.0, 2, 1.0, 8.0], [4, -2.0, 1, 1.0, 2.0], [5, -1.0, 0, 0, -2.0], [0, 0, 5, 1.0, 27.0], [1, -1.0, 4, 1.0, 21.0], [2, -1.0, 3, 1.0, 15.0], [3, -1.0, 2, 1.0, 9.0], [4, -1.0, 1, 1.0, 3.0], [5, -1.0, 0, 0, -3.0], [1, -1.0, 4, 5.0, 115.0], [2, -1.0, 3, 5.0, 85.0], [3, -1.0, 2, 5.0, 55.0], [0, 0, 5, 1.0, 29.0], [4, -1.0, 1, 5.0, 25.0], [5, -1.0, 0, 0, -5.0], [0, 0, 6, 1.0, 26.0], [1, -4.0, 5, 1.0, 21.0], [2, -4.0, 4, 1.0, 16.0], [3, -4.0, 3, 1.0, 11.0], [4, -4.0, 2, 1.0, 6.0], [5, -4.0, 1, 1.0, 1.0], [6, -1.0, 0, 0, -1.0], [0, 0, 6, 1.0, 27.0], [1, -1.5, 5, 1.0, 22.0], [2, -1.5, 4, 1.0, 17.0], [3, -1.5, 3, 1.0, 12.0], [4, -1.5, 2, 1.0, 7.0], [5, -1.5, 1, 1.0, 2.0], [6, -1.0, 0, 0, -2.0], [1, -1.0, 5, 1.5, 34.5], [0, 0, 6, 1.0, 28.0], [2, -1.0, 4, 1.5, 27.0], [3, -1.0, 3, 1.5, 19.5], [4, -1.0, 2, 1.5, 12.0], [5, -1.0, 1, 1.5, 4.5], [6, -1.0, 0, 0, -3.0], [1, -1.0, 5, 4.0, 96.0], [2, -1.0, 4, 4.0, 76.0], [3, -1.0, 3, 4.0, 56.0], [4, -1.0, 2, 4.0, 36.0], [0, 0, 6, 1.0, 29.0], [5, -1.0, 1, 4.0, 16.0], [6, -1.0, 0, 0, -4.0], [0, 0, 3, 1.0, 9.0], [1, -1.5, 2, 1.0, 4.0], [2, -1.5, 1, 1.0, -1.0], [3, -1.0, 0, 0, -4.0], [0, 0, 3, 1.0, 10.0], [1, -2.0, 2, 1.0, 4.0], [2, -2.0, 1, 1.0, -2.0], [3, -1.0, 0, 0, -4.0], [0, 0, 3, 1.0, 12.0], [1, -1.0, 2, 1.0, 6.0], [2, -1.0, 1, 1.0, 0.0], [3, -1.0, 0, 0, -6.0], [0, 0, 4, 1.0, 14.0], [1, -5.0, 3, 1.0, 8.0], [2, -5.0, 2, 1.0, 2.0], [4, -1.0, 0, 0, -2.0], [3, -5.0, 1, 1.0, -4.0], [0, 0, 4, 1.0, 16.0], [1, -2.0, 3, 1.0, 10.0], [2, -2.0, 2, 1.0, 4.0], [3, -2.0, 1, 1.0, -2.0], [4, -1.0, 0, 0, -4.0], [0, 0, 4, 1.0, 18.0], [1, -1.0, 3, 1.0, 12.0], [2, -1.0, 2, 1.0, 6.0], [3, -1.0, 1, 1.0, 0.0], [4, -1.0, 0, 0, -6.0], [1, -1.0, 3, 2.0, 28.0], [0, 0, 4, 1.0, 20.0], [2, -1.0, 2, 2.0, 16.0], [3, -1.0, 1, 2.0, 4.0], [4, -1.0, 0, 0, -8.0], [1, -1.0, 3, 5.0, 80.0], [2, -1.0, 2, 5.0, 50.0], [0, 0, 4, 1.0, 22.0], [3, -1.0, 1, 5.0, 20.0], [4, -1.0, 0, 0, -10.0], [0, 0, 5, 1.0, 20.0], [1, -5.0, 4, 1.0, 14.0], [2, -5.0, 3, 1.0, 8.0], [3, -5.0, 2, 1.0, 2.0], [5, -1.0, 0, 0, -2.0], [4, -5.0, 1, 1.0, -4.0], [0, 0, 5, 1.0, 22.0], [1, -2.0, 4, 1.0, 16.0], [2, -2.0, 3, 1.0, 10.0], [3, -2.0, 2, 1.0, 4.0], [4, -2.0, 1, 1.0, -2.0], [5, -1.0, 0, 0, -4.0], [1, -1.0, 4, 1.5, 24.0], [0, 0, 5, 1.0, 21.0], [2, -1.0, 3, 1.5, 16.5], [3, -1.0, 2, 1.5, 9.0], [4, -1.0, 1, 1.5, 1.5], [5, -1.0, 0, 0, -6.0], [0, 0, 5, 1.0, 24.0], [1, -1.0, 4, 1.0, 18.0], [2, -1.0, 3, 1.0, 12.0], [3, -1.0, 2, 1.0, 6.0], [4, -1.0, 1, 1.0, 0.0], [5, -1.0, 0, 0, -6.0], [1, -1.0, 4, 2.0, 40.0], [2, -1.0, 3, 2.0, 28.0], [0, 0, 5, 1.0, 26.0], [3, -1.0, 2, 2.0, 16.0], [4, -1.0, 1, 2.0, 4.0], [5, -1.0, 0, 0, -8.0], [0, 0, 6, 1.0, 22.0], [1, -4.0, 5, 1.0, 17.0], [2, -4.0, 4, 1.0, 12.0], [3, -4.0, 3, 1.0, 7.0], [4, -4.0, 2, 1.0, 2.0], [6, -1.0, 0, 0, -2.0], [5, -4.0, 1, 1.0, -3.0], [0, 0, 6, 1.0, 24.0], [1, -1.5, 5, 1.0, 19.0], [2, -1.5, 4, 1.0, 14.0], [3, -1.5, 3, 1.0, 9.0], [4, -1.5, 2, 1.0, 4.0], [5, -1.5, 1, 1.0, -1.0], [6, -1.0, 0, 0, -4.0], [1, -1.0, 5, 1.5, 31.5], [0, 0, 6, 1.0, 26.0], [2, -1.0, 4, 1.5, 24.0], [3, -1.0, 3, 1.5, 16.5], [4, -1.0, 2, 1.5, 9.0], [5, -1.0, 1, 1.5, 1.5], [6, -1.0, 0, 0, -6.0], [0, 0, 6, 1.0, 30.0], [1, -1.0, 5, 1.0, 24.0], [2, -1.0, 4, 1.0, 18.0], [3, -1.0, 3, 1.0, 12.0], [4, -1.0, 2, 1.0, 6.0], [5, -1.0, 1, 1.0, 0.0], [6, -1.0, 0, 0, -6.0], [1, -1.0, 5, 4.0, 92.0], [2, -1.0, 4, 4.0, 72.0], [3, -1.0, 3, 4.0, 52.0], [4, -1.0, 2, 4.0, 32.0], [0, 0, 6, 1.0, 28.0], [5, -1.0, 1, 4.0, 12.0], [6, -1.0, 0, 0, -8.0], [0, 0, 7, 1.0, 36.0], [1, -1.0, 6, 1.0, 30.0], [2, -1.0, 5, 1.0, 24.0], [3, -1.0, 4, 1.0, 18.0], [4, -1.0, 3, 1.0, 12.0], [5, -1.0, 2, 1.0, 6.0], [6, -1.0, 1, 1.0, 0.0], [7, -1.0, 0, 0, -6.0], [0, 0, 4, 1.0, 9.0], [1, -5.0, 3, 1.0, 3.0], [2, -5.0, 2, 1.0, -3.0], [3, -5.0, 1, 1.0, -9.0], [0, 0, 4, 1.0, 12.0], [1, -2.0, 3, 1.0, 6.0], [2, -2.0, 2, 1.0, 0.0], [3, -2.0, 1, 1.0, -6.0], [0, 0, 4, 1.0, 15.0], [1, -1.0, 3, 1.0, 9.0], [2, -1.0, 2, 1.0, 3.0], [3, -1.0, 1, 1.0, -3.0], [4, -1.0, 0, 0, -9.0], [1, -1.0, 3, 2.0, 24.0], [0, 0, 4, 1.0, 18.0], [2, -1.0, 2, 2.0, 12.0], [3, -1.0, 1, 2.0, 0.0], [4, -1.0, 0, 0, -12.0], [1, -1.0, 3, 5.0, 75.0], [2, -1.0, 2, 5.0, 45.0], [0, 0, 4, 1.0, 21.0], [3, -1.0, 1, 5.0, 15.0], [4, -1.0, 0, 0, -15.0], [0, 0, 5, 1.0, 18.0], [1, -2.0, 4, 1.0, 12.0], [2, -2.0, 3, 1.0, 6.0], [2, -2.0, 3, 1.0, 6.0], [3, -2.0, 2, 1.0, 0.0], [3, -2.0, 2, 1.0, 0.0], [4, -2.0, 1, 1.0, -6.0], [0, 0, 5, 1.0, 21.0], [1, -1.0, 4, 1.0, 15.0], [2, -1.0, 3, 1.0, 9.0], [3, -1.0, 2, 1.0, 3.0], [4, -1.0, 1, 1.0, -3.0], [5, -1.0, 0, 0, -9.0], [1, -1.0, 4, 2.0, 36.0], [2, -1.0, 3, 2.0, 24.0], [3, -1.0, 2, 2.0, 12.0], [4, -1.0, 1, 2.0, 0.0], [4, -1.0, 1, 2.0, 0.0], [5, -1.0, 0, 0, -12.0], [1, -1.0, 4, 5.0, 105.0], [2, -1.0, 3, 5.0, 75.0], [3, -1.0, 2, 5.0, 45.0], [0, 0, 5, 1.0, 27.0], [4, -1.0, 1, 5.0, 15.0], [5, -1.0, 0, 0, -15.0], [0, 0, 6, 1.0, 18.0], [1, -4.0, 5, 1.0, 13.0], [2, -4.0, 4, 1.0, 8.0], [3, -4.0, 3, 1.0, 3.0], [4, -4.0, 2, 1.0, -2.0], [6, -1.0, 0, 0, -3.0], [5, -4.0, 1, 1.0, -7.0], [0, 0, 6, 1.0, 21.0], [1, -1.5, 5, 1.0, 16.0], [2, -1.5, 4, 1.0, 11.0], [3, -1.5, 3, 1.0, 6.0], [4, -1.5, 2, 1.0, 1.0], [5, -1.5, 1, 1.0, -4.0], [6, -1.0, 0, 0, -6.0], [1, -1.0, 5, 1.5, 28.5], [0, 0, 6, 1.0, 24.0], [2, -1.0, 4, 1.5, 21.0], [3, -1.0, 3, 1.5, 13.5], [4, -1.0, 2, 1.5, 6.0], [5, -1.0, 1, 1.5, -1.5], [6, -1.0, 0, 0, -9.0], [1, -1.0, 5, 4.0, 88.0], [2, -1.0, 4, 4.0, 68.0], [3, -1.0, 3, 4.0, 48.0], [4, -1.0, 2, 4.0, 28.0], [0, 0, 6, 1.0, 27.0], [5, -1.0, 1, 4.0, 8.0], [6, -1.0, 0, 0, -12.0], [0, 0, 5, 1.0, 10.0], [1, -5.0, 4, 1.0, 4.0], [2, -5.0, 3, 1.0, -2.0], [5, -1.0, 0, 0, -4.0], [3, -5.0, 2, 1.0, -8.0], [4, -5.0, 1, 1.0, -14.0], [0, 0, 5, 1.0, 14.0], [1, -2.0, 4, 1.0, 8.0], [2, -2.0, 3, 1.0, 2.0], [3, -2.0, 2, 1.0, -4.0], [5, -1.0, 0, 0, -8.0], [4, -2.0, 1, 1.0, -10.0], [0, 0, 5, 1.0, 18.0], [1, -1.0, 4, 1.0, 12.0], [2, -1.0, 3, 1.0, 6.0], [3, -1.0, 2, 1.0, 0.0], [4, -1.0, 1, 1.0, -6.0], [5, -1.0, 0, 0, -12.0], [1, -1.0, 4, 2.0, 32.0], [0, 0, 5, 1.0, 22.0], [2, -1.0, 3, 2.0, 20.0], [3, -1.0, 2, 2.0, 8.0], [4, -1.0, 1, 2.0, -4.0], [5, -1.0, 0, 0, -16.0], [1, -1.0, 4, 5.0, 100.0], [2, -1.0, 3, 5.0, 70.0], [3, -1.0, 2, 5.0, 40.0], [0, 0, 5, 1.0, 26.0], [4, -1.0, 1, 5.0, 10.0], [5, -1.0, 0, 0, -20.0], [0, 0, 6, 1.0, 14.0], [1, -4.0, 5, 1.0, 9.0], [2, -4.0, 4, 1.0, 4.0], [3, -4.0, 3, 1.0, -1.0], [6, -1.0, 0, 0, -4.0], [4, -4.0, 2, 1.0, -6.0], [5, -4.0, 1, 1.0, -11.0], [0, 0, 6, 1.0, 18.0], [1, -1.5, 5, 1.0, 13.0], [2, -1.5, 4, 1.0, 8.0], [3, -1.5, 3, 1.0, 3.0], [4, -1.5, 2, 1.0, -2.0], [5, -1.5, 1, 1.0, -7.0], [6, -1.0, 0, 0, -8.0], [1, -1.0, 5, 1.5, 25.5], [0, 0, 6, 1.0, 22.0], [2, -1.0, 4, 1.5, 18.0], [3, -1.0, 3, 1.5, 10.5], [4, -1.0, 2, 1.5, 3.0], [5, -1.0, 1, 1.5, -4.5], [6, -1.0, 0, 0, -12.0], [1, -1.0, 5, 4.0, 84.0], [2, -1.0, 4, 4.0, 64.0], [3, -1.0, 3, 4.0, 44.0], [0, 0, 6, 1.0, 26.0], [4, -1.0, 2, 4.0, 24.0], [5, -1.0, 1, 4.0, 4.0], [6, -1.0, 0, 0, -16.0]]\n"
     ]
    }
   ],
   "source": [
    "clusterList = []\n",
    "clusterList44 = {}\n",
    "\n",
    "for i in Y_prediction:\n",
    "    if i not in clusterList:\n",
    "        clusterList.append(i)\n",
    "        \n",
    "for i in clusterList:\n",
    "    clusterList44[i] = []\n",
    "\n",
    "k=0\n",
    "\n",
    "for i in Y_prediction:\n",
    "    if i in clusterList44:\n",
    "        clusterList44[i].append(fiveList[k][0:5])\n",
    "    k+=1\n",
    "\n",
    "print 'ZEROS CLUSTER',' ',clusterList44[0],'\\n'\n",
    "print 'ONES CLUSTER',' ',clusterList44[1],'\\n'\n",
    "print 'TWOS CLUSTER',' ',clusterList44[2],'\\n'\n",
    "print 'NEGATIVE ONE CLUSTER',' ',clusterList44[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
